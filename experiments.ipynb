{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spatio-Temporal Traffic Forecasting with Neural Graph Cellular Automata\n",
    "Petrônio C.  L. Silva  <span itemscope itemtype=\"https://schema.org/Person\"><a itemprop=\"sameAs\" content=\"https://orcid.org/0000-0002-1202-2552\" href=\"https://orcid.org/0000-0002-1202-2552\" target=\"orcid.widget\" rel=\"noopener noreferrer\" style=\"vertical-align:top;\"><img src=\"https://orcid.org/sites/default/files/images/orcid_16x16.png\" style=\"width:1em;margin-right:.5em;\" alt=\"ORCID iD icon\"></a></span>, Omid Orang  <span itemscope itemtype=\"https://schema.org/Person\"><a itemprop=\"sameAs\" content=\"https://orcid.org/0000-0002-4077-3775\" href=\"https://orcid.org/0000-0002-4077-3775\" target=\"orcid.widget\" rel=\"noopener noreferrer\" style=\"vertical-align:top;\"><img src=\"https://orcid.org/sites/default/files/images/orcid_16x16.png\" style=\"width:1em;margin-right:.5em;\" alt=\"ORCID iD icon\"></a></span>, Lucas Astore, Frederico G. Guimarães <span itemscope itemtype=\"https://schema.org/Person\"><a itemprop=\"sameAs\" content=\"https://orcid.org/0000-0001-9238-8839\" href=\"https://orcid.org/0000-0001-9238-8839\" target=\"orcid.widget\" rel=\"noopener noreferrer\" style=\"vertical-align:top;\"><img src=\"https://orcid.org/sites/default/files/images/orcid_16x16.png\" style=\"width:1em;margin-right:.5em;\" alt=\"ORCID iD icon\"></a></span>\n",
    "\n",
    "In case you have any questions, do not hesitate in contact us using the following e-mail: petronio.candido@ifnmg.edu.br\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "from st_nca.common import resume, get_device, checkpoint_all\n",
    "from st_nca.datasets.PEMS import PEMS04, get_config as pems_get_config\n",
    "from st_nca.cellmodel import CellModel, load_config, get_config\n",
    "from st_nca.pretrain import training_loop\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = get_device()\n",
    "DTYPE = torch.float32\n",
    "#DEFAULT_PATH = 'C:\\\\Users\\\\petro\\\\Dropbox\\\\Projetos\\\\futurelab\\\\posdoc\\\\st_nca\\\\st_nca\\\\st_nca\\\\'\n",
    "DEFAULT_PATH = 'D:\\\\Dropbox\\\\Projetos\\\\futurelab\\\\posdoc\\\\st_nca\\\\st_nca\\\\st_nca\\\\'\n",
    "DATA_PATH = DEFAULT_PATH + 'data\\\\PEMS04\\\\'\n",
    "MODELS_PATH = DEFAULT_PATH + 'weights\\\\PEMS04\\\\'\n",
    "\n",
    "STEPS_AHEAD = 1\n",
    "ITERATIONS = 1\n",
    "\n",
    "pems = PEMS04(edges_file = DATA_PATH + 'edges.csv', data_file = DATA_PATH + 'data.csv',\n",
    "    device = DEVICE, dtype = DTYPE, steps_ahead = STEPS_AHEAD)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pems.max_length\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313658\n"
     ]
    }
   ],
   "source": [
    "sensor_index = 10\n",
    "sensor = pems.get_sensor(sensor_index)\n",
    "print(sensor)\n",
    "sample_index = 10\n",
    "\n",
    "ds1 = pems.get_sensor_dataset(sensor, dtype=torch.float32, behavior='deterministic')\n",
    "ds2 = pems.get_allsensors_dataset(behavior='deterministic')\n",
    "\n",
    "#pems.to_tensordict()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "shape '[16992, 3, 7]' is invalid for input of size 254880",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m ds \u001b[38;5;241m=\u001b[39m \u001b[43mpems\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_sensor_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m300\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat32\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbehavior\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdeterministic\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m#ds = pems.get_allsensors_dataset(behavior='deterministic')\u001b[39;00m\n\u001b[0;32m      3\u001b[0m ds\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__dict__\u001b[39m\n",
      "File \u001b[1;32md:\\Dropbox\\Projetos\\futurelab\\posdoc\\st_nca\\st_nca\\st_nca\\datasets\\PEMS.py:124\u001b[0m, in \u001b[0;36mPEMSBase.get_sensor_dataset\u001b[1;34m(self, sensor, train, dtype, **kwargs)\u001b[0m\n\u001b[0;32m    123\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_sensor_dataset\u001b[39m(\u001b[38;5;28mself\u001b[39m, sensor, train \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.7\u001b[39m, dtype \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mfloat64, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m--> 124\u001b[0m   X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtokenizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtokenize_all\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msensor\u001b[49m\u001b[43m)\u001b[49m[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m    125\u001b[0m   y \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata[\u001b[38;5;28mstr\u001b[39m(sensor)]\u001b[38;5;241m.\u001b[39mvalues[\u001b[38;5;241m1\u001b[39m:], dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdtype, device\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[0;32m    126\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m SensorDataset(\u001b[38;5;28mstr\u001b[39m(sensor),X,y,train, dtype, num_features \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_sensors,\n\u001b[0;32m    127\u001b[0m                        max_length\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_length, token_dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtoken_dim,\n\u001b[0;32m    128\u001b[0m                        value_index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvalue_index, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32md:\\Dropbox\\Projetos\\futurelab\\posdoc\\st_nca\\st_nca\\st_nca\\tokenizer.py:92\u001b[0m, in \u001b[0;36mNeighborhoodTokenizer.tokenize_all\u001b[1;34m(self, data, sensor)\u001b[0m\n\u001b[0;32m     89\u001b[0m   tokens \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mhstack([tokens, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnormalized_data(data, neighbor)\u001b[38;5;241m.\u001b[39mreshape(n,\u001b[38;5;241m1\u001b[39m) ])\n\u001b[0;32m     90\u001b[0m   tokens \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mhstack([tokens, tim_emb])\n\u001b[1;32m---> 92\u001b[0m tokens \u001b[38;5;241m=\u001b[39m \u001b[43mtokens\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreshape\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtoken_dim\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     95\u001b[0m tokens \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mhstack([tokens, torch\u001b[38;5;241m.\u001b[39mfull((n,  \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_length \u001b[38;5;241m-\u001b[39m m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtoken_dim), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mNULL_SYMBOL,\n\u001b[0;32m     96\u001b[0m                                           dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdtype, device \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)])\n\u001b[0;32m     98\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m tokens\n",
      "\u001b[1;31mRuntimeError\u001b[0m: shape '[16992, 3, 7]' is invalid for input of size 254880"
     ]
    }
   ],
   "source": [
    "ds = pems.get_sensor_dataset(300, dtype=torch.float32, behavior='deterministic')\n",
    "#ds = pems.get_allsensors_dataset(behavior='deterministic')\n",
    "ds.__dict__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "shape '[16992, 3, 7]' is invalid for input of size 254880",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 23\u001b[0m\n\u001b[0;32m     20\u001b[0m CHECKPOINT_FILE \u001b[38;5;241m=\u001b[39m MODELS_PATH \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcm3x16x1024_h1.pt\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;66;03m#ds = pems.get_fewsensors_dataset([311930, 312564, 312807, 312900, 313172, 314697, 315938, 317141, 318135, 318443 ], dtype=torch.float32, behavior='selfsupervised')\u001b[39;00m\n\u001b[1;32m---> 23\u001b[0m ds \u001b[38;5;241m=\u001b[39m \u001b[43mpems\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_sensor_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m300\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat32\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbehavior\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdeterministic\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;66;03m#ds, sensors = pems.get_breadth_dataset(314697, max_sensors=20,  dtype=DTYPE,  behavior='selfsupervised')\u001b[39;00m\n\u001b[0;32m     25\u001b[0m \u001b[38;5;66;03m#print(sensors)\u001b[39;00m\n\u001b[0;32m     26\u001b[0m \n\u001b[0;32m     27\u001b[0m \u001b[38;5;66;03m#pems.to_tensordict()\u001b[39;00m\n\u001b[0;32m     28\u001b[0m \n\u001b[0;32m     29\u001b[0m \u001b[38;5;66;03m#ds = pems.get_allsensors_dataset(behavior='deterministic')\u001b[39;00m\n\u001b[0;32m     31\u001b[0m ds \u001b[38;5;241m=\u001b[39m ds\u001b[38;5;241m.\u001b[39mto(DEVICE)\n",
      "File \u001b[1;32md:\\Dropbox\\Projetos\\futurelab\\posdoc\\st_nca\\st_nca\\st_nca\\datasets\\PEMS.py:124\u001b[0m, in \u001b[0;36mPEMSBase.get_sensor_dataset\u001b[1;34m(self, sensor, train, dtype, **kwargs)\u001b[0m\n\u001b[0;32m    123\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_sensor_dataset\u001b[39m(\u001b[38;5;28mself\u001b[39m, sensor, train \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.7\u001b[39m, dtype \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mfloat64, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m--> 124\u001b[0m   X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtokenizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtokenize_all\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msensor\u001b[49m\u001b[43m)\u001b[49m[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m    125\u001b[0m   y \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata[\u001b[38;5;28mstr\u001b[39m(sensor)]\u001b[38;5;241m.\u001b[39mvalues[\u001b[38;5;241m1\u001b[39m:], dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdtype, device\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[0;32m    126\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m SensorDataset(\u001b[38;5;28mstr\u001b[39m(sensor),X,y,train, dtype, num_features \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_sensors,\n\u001b[0;32m    127\u001b[0m                        max_length\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_length, token_dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtoken_dim,\n\u001b[0;32m    128\u001b[0m                        value_index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvalue_index, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32md:\\Dropbox\\Projetos\\futurelab\\posdoc\\st_nca\\st_nca\\st_nca\\tokenizer.py:92\u001b[0m, in \u001b[0;36mNeighborhoodTokenizer.tokenize_all\u001b[1;34m(self, data, sensor)\u001b[0m\n\u001b[0;32m     89\u001b[0m   tokens \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mhstack([tokens, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnormalized_data(data, neighbor)\u001b[38;5;241m.\u001b[39mreshape(n,\u001b[38;5;241m1\u001b[39m) ])\n\u001b[0;32m     90\u001b[0m   tokens \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mhstack([tokens, tim_emb])\n\u001b[1;32m---> 92\u001b[0m tokens \u001b[38;5;241m=\u001b[39m \u001b[43mtokens\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreshape\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtoken_dim\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     95\u001b[0m tokens \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mhstack([tokens, torch\u001b[38;5;241m.\u001b[39mfull((n,  \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_length \u001b[38;5;241m-\u001b[39m m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtoken_dim), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mNULL_SYMBOL,\n\u001b[0;32m     96\u001b[0m                                           dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdtype, device \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)])\n\u001b[0;32m     98\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m tokens\n",
      "\u001b[1;31mRuntimeError\u001b[0m: shape '[16992, 3, 7]' is invalid for input of size 254880"
     ]
    }
   ],
   "source": [
    "config = {\n",
    "    'num_tokens': pems.max_length,\n",
    "    'dim_token': pems.token_dim,\n",
    "    'num_transformers': 3,\n",
    "    'num_heads': 16,\n",
    "    'transformer_feed_forward': 1024,\n",
    "    'transformer_activation': nn.GELU(approximate='none'),\n",
    "    'normalization': torch.nn.modules.normalization.LayerNorm,\n",
    "    'pre_norm': False,\n",
    "    'feed_forward': 3,\n",
    "    'feed_forward_dim': 1024,\n",
    "    'feed_forward_activation': nn.GELU(approximate='none'),\n",
    "    'device': 'cpu',\n",
    "    'dtype': torch.float32,\n",
    "    'steps_ahead': 12\n",
    " }\n",
    "\n",
    "MODELS_PATH = DEFAULT_PATH + 'weights\\\\PEMS04\\\\'\n",
    "\n",
    "CHECKPOINT_FILE = MODELS_PATH + 'cm3x16x1024_h1.pt'\n",
    "\n",
    "#ds = pems.get_fewsensors_dataset([311930, 312564, 312807, 312900, 313172, 314697, 315938, 317141, 318135, 318443 ], dtype=torch.float32, behavior='selfsupervised')\n",
    "ds = pems.get_sensor_dataset(300, dtype=torch.float32, behavior='deterministic')\n",
    "#ds, sensors = pems.get_breadth_dataset(314697, max_sensors=20,  dtype=DTYPE,  behavior='selfsupervised')\n",
    "#print(sensors)\n",
    "\n",
    "#pems.to_tensordict()\n",
    "\n",
    "#ds = pems.get_allsensors_dataset(behavior='deterministic')\n",
    "\n",
    "ds = ds.to(DEVICE)\n",
    "\n",
    "cm = load_config(config)\n",
    "\n",
    "#resume(cm, MODELS_PATH + 'PEMS03_cell_model_2_4_256_2_256_20241214.pt')\n",
    "\n",
    "\n",
    "#resume(cm, CHECKPOINT_FILE)\n",
    "\n",
    "training_loop(DEVICE, ds, cm,  batch=2048, epochs=10, lr=0.001,\n",
    "              checkpoint_file= CHECKPOINT_FILE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from st_nca.common import MAPE, SMAPE\n",
    "def evaluate(model, in_sample, out_sample, num_samples = None):\n",
    "  metrics = {\"MAPE\": MAPE, \"SMAPE\": SMAPE}\n",
    "\n",
    "  model.eval()\n",
    "\n",
    "  results = {}\n",
    "\n",
    "  results['train'] = experiment_on_dataset(model, in_sample, num_samples, metrics)\n",
    "  results['test'] = experiment_on_dataset(model, out_sample, num_samples, metrics)\n",
    "\n",
    "  return results\n",
    "\n",
    "def experiment_on_dataset(model, sample, num_samples, metrics):\n",
    "    total = len(sample)\n",
    "    samples = num_samples if not num_samples is None else total\n",
    "    indexes = torch.randperm(total, device=model.device)[:samples]\n",
    "\n",
    "    X_batch = torch.zeros(samples, model.num_tokens, model.dim_token, \n",
    "                      device=model.device, dtype=model.dtype)\n",
    "    y_batch = torch.zeros(samples, device=model.device, dtype=model.dtype)\n",
    "  \n",
    "    for ct,ix in enumerate(indexes):\n",
    "      X,y = sample[ix]\n",
    "      X_batch[ct,:] = X\n",
    "      y_batch[ct] = y\n",
    "\n",
    "    #print(X_batch, y_batch)\n",
    "\n",
    "    out = model(X_batch)\n",
    "\n",
    "    #print(out)\n",
    "\n",
    "    res = {}\n",
    "    for key, metric in metrics.items():\n",
    "      res[key] = metric(y_batch, out).detach().cpu()\n",
    "\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train': {'MAPE': tensor(2.4232e+08), 'SMAPE': tensor(0.8460)},\n",
       " 'test': {'MAPE': tensor(2.0427e+08), 'SMAPE': tensor(0.8683)}}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NTRANSF = 2\n",
    "NHEADS = 4\n",
    "NTRANSFF = 256\n",
    "TRANSFACT = nn.GELU()\n",
    "MLP = 2\n",
    "MLPD = 256\n",
    "MLPACT = nn.GELU()\n",
    "\n",
    "MODELS_PATH = DEFAULT_PATH + 'weights\\\\PEMS03\\\\'\n",
    "\n",
    "CHECKPOINT_FILE = MODELS_PATH + 'cell_model_{}_{}_{}_{}_{}.pt'.format(NTRANSF,NHEADS,NTRANSFF,MLP,MLPD)\n",
    "\n",
    "pems.to_tensordict()\n",
    "\n",
    "ds = pems.get_allsensors_dataset(behavior='selfsupervised')\n",
    "\n",
    "ds = ds.to(DEVICE)\n",
    "\n",
    "cm = CellModel(num_tokens = ds.max_length, dim_token = ds.token_dim,\n",
    "               num_transformers = NTRANSF, num_heads = NHEADS, feed_forward = NTRANSFF, \n",
    "               transformer_activation = TRANSFACT,\n",
    "               mlp = MLP, mlp_dim = MLPD, mlp_activation = MLPACT,\n",
    "               use_moe = False, num_experts = 8,\n",
    "               device = DEVICE, dtype = DTYPE)\n",
    "\n",
    "resume(cm, CHECKPOINT_FILE)\n",
    "\n",
    "evaluate(model=cm, in_sample=ds.train(), out_sample=ds.test(), num_samples=15000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment Agenda\n",
    "\n",
    "Federated Graph Neural Cellular Automata - FedGNCA\n",
    "\n",
    "#### Cross Validation\n",
    "\n",
    "- 60% Training\n",
    "- 20% Validation\n",
    "- 20% Test\n",
    "\n",
    "#### H = Forecasting Horizons\n",
    "\n",
    "- ~H = 1 (5 minutes ahead)~\n",
    "- H = 12 (1 hour ahead)\n",
    "- ~H = 24 (2 hours ahead)~\n",
    "- ~H = 48 (4 hours ahead)~\n",
    "- ~H = 96 (8 hours ahead)~\n",
    "\n",
    "#### Metrics\n",
    "- Loss Function: MSE\n",
    "- Comparison Metrics\n",
    "  - MAPE \n",
    "  - RMSE\n",
    "  - MAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pems.num_samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graph CA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODELS_PATH = DEFAULT_PATH + 'weights\\\\PEMS03\\\\'\n",
    "\n",
    "DTYPE = torch.float32\n",
    "NTRANSF = 2\n",
    "NHEADS = 4\n",
    "NTRANSFF = 256\n",
    "TRANSFACT = nn.GELU()\n",
    "MLP = 2\n",
    "MLPD = 256\n",
    "MLPACT = nn.GELU()\n",
    "\n",
    "ds, sensors = pems.get_breadth_dataset(314697, max_sensors=20, \n",
    "                                       dtype=torch.float64,\n",
    "                                       behavior='deterministic')\n",
    "\n",
    "cm = CellModel(num_tokens = ds.max_length, dim_token = ds.token_dim,\n",
    "               num_transformers = NTRANSF, num_heads = NHEADS, feed_forward = NTRANSFF, \n",
    "               transformer_activation = TRANSFACT,\n",
    "               mlp = MLP, mlp_dim = MLPD, mlp_activation = MLPACT,\n",
    "               device = DEVICE, dtype = DTYPE)\n",
    "\n",
    "resume(cm, MODELS_PATH + 'cell_model_{}_{}_{}_{}_{}.pt'.format(NTRANSF,NHEADS,NTRANSFF,MLP,MLPD))\n",
    "\n",
    "subgraph = pems.G.subgraph(sensors)\n",
    "\n",
    "gca = GraphCellularAutomata(device=cm.device, dtype=cm.dtype, graph = subgraph,\n",
    "                            max_length = pems.max_length, token_size=pems.token_dim,\n",
    "                            tokenizer=pems.tokenizer, cell_model = cm)\n",
    "\n",
    "initial_date = datetime(year=2018, month=9, day=1, hour=23, minute=0)\n",
    "\n",
    "df = pems.data[(pems.data['timestamp'] == from_datetime_to_np(initial_date))]\n",
    "\n",
    "initial_state = {}\n",
    "for sensor in subgraph.nodes():\n",
    "    initial_state[str(sensor)] = df[str(sensor)].values[0]\n",
    "\n",
    "print(initial_state)\n",
    "\n",
    "gca.run(initial_date = initial_date, initial_stat = initial_state, \n",
    "        iterations = 10, increment_type='minute', increment=5,\n",
    "        return_type = 'tensordict')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine Tunning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from st_nca.finetune import FineTunningDataset, finetune_loop\n",
    "\n",
    "MODELS_PATH = DEFAULT_PATH + 'weights\\\\PEMS03\\\\'\n",
    "\n",
    "DTYPE = torch.float32\n",
    "NTRANSF = 2\n",
    "NHEADS = 4\n",
    "NTRANSFF = 256\n",
    "TRANSFACT = nn.GELU()\n",
    "MLP = 2\n",
    "MLPD = 256\n",
    "MLPACT = nn.GELU()\n",
    "\n",
    "ds, sensors = pems.get_breadth_dataset(314697, max_sensors=20, \n",
    "                                       dtype=DTYPE,\n",
    "                                       behavior='deterministic')\n",
    "\n",
    "cm = CellModel(num_tokens = ds.max_length, dim_token = ds.token_dim,\n",
    "               num_transformers = NTRANSF, num_heads = NHEADS, feed_forward = NTRANSFF, \n",
    "               transformer_activation = TRANSFACT,\n",
    "               mlp = MLP, mlp_dim = MLPD, mlp_activation = MLPACT,\n",
    "               device = DEVICE, dtype = DTYPE)\n",
    "\n",
    "resume(cm, MODELS_PATH + 'cell_model_{}_{}_{}_{}_{}.pt'.format(NTRANSF,NHEADS,NTRANSFF,MLP,MLPD))\n",
    "\n",
    "subgraph = pems.G.subgraph(sensors)\n",
    "\n",
    "gca = GraphCellularAutomata(device=DEVICE, dtype=DTYPE, graph = subgraph,\n",
    "                            max_length = pems.max_length, token_size=pems.token_dim,\n",
    "                            tokenizer=pems.tokenizer, cell_model = cm)\n",
    "\n",
    "finetune_ds = FineTunningDataset(pems, sensors, )\n",
    "\n",
    "finetune_loop(DEVICE, finetune_ds, gca, \n",
    "              iterations = 10, increment_type='minute', increment=5,\n",
    "              epochs = 10, batch = 50, lr = 0.0001,\n",
    "              checkpoint_file =  MODELS_PATH + 'gca_{}_{}_{}_{}_{}.pt'.format(NTRANSF,NHEADS,NTRANSFF,MLP,MLPD))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pems.num_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
