{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spatio-Temporal Traffic Forecasting with Neural Graph Cellular Automata\n",
    "Petrônio C.  L. Silva  <span itemscope itemtype=\"https://schema.org/Person\"><a itemprop=\"sameAs\" content=\"https://orcid.org/0000-0002-1202-2552\" href=\"https://orcid.org/0000-0002-1202-2552\" target=\"orcid.widget\" rel=\"noopener noreferrer\" style=\"vertical-align:top;\"><img src=\"https://orcid.org/sites/default/files/images/orcid_16x16.png\" style=\"width:1em;margin-right:.5em;\" alt=\"ORCID iD icon\"></a></span>, Omid Orang  <span itemscope itemtype=\"https://schema.org/Person\"><a itemprop=\"sameAs\" content=\"https://orcid.org/0000-0002-4077-3775\" href=\"https://orcid.org/0000-0002-4077-3775\" target=\"orcid.widget\" rel=\"noopener noreferrer\" style=\"vertical-align:top;\"><img src=\"https://orcid.org/sites/default/files/images/orcid_16x16.png\" style=\"width:1em;margin-right:.5em;\" alt=\"ORCID iD icon\"></a></span>, Lucas Astore, Frederico G. Guimarães <span itemscope itemtype=\"https://schema.org/Person\"><a itemprop=\"sameAs\" content=\"https://orcid.org/0000-0001-9238-8839\" href=\"https://orcid.org/0000-0001-9238-8839\" target=\"orcid.widget\" rel=\"noopener noreferrer\" style=\"vertical-align:top;\"><img src=\"https://orcid.org/sites/default/files/images/orcid_16x16.png\" style=\"width:1em;margin-right:.5em;\" alt=\"ORCID iD icon\"></a></span>\n",
    "\n",
    "In case you have any questions, do not hesitate in contact us using the following e-mail: petronio.candido@ifnmg.edu.br\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, timezone, timedelta\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "\n",
    "from sklearn.manifold import SpectralEmbedding\n",
    "\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from tensordict import TensorDict\n",
    "\n",
    "from st_nca.common import get_device, resume, checkpoint\n",
    "from st_nca.datasets.PEMS import PEMS03\n",
    "from st_nca.datasets.datasets import SensorDataset\n",
    "from st_nca.cellmodel import CellModel\n",
    "from st_nca.pretrain import training_loop, evaluate\n",
    "from st_nca.gca import GraphCellularAutomata\n",
    "\n",
    "from st_nca.embeddings.temporal import from_datetime_to_pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\petro\\Dropbox\\Projetos\\futurelab\\posdoc\\st_nca\\st_nca\\st_nca\\embeddings\\normalization.py:15: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  data = torch.tensor(data, dtype=self.dtype, device=self.device)\n"
     ]
    }
   ],
   "source": [
    "DEVICE = get_device()\n",
    "DTYPE = torch.float32\n",
    "\n",
    "DEFAULT_PATH = 'C:\\\\Users\\\\petro\\\\Dropbox\\\\Projetos\\\\futurelab\\\\posdoc\\\\st_nca\\\\st_nca\\\\st_nca\\\\'\n",
    "\n",
    "\n",
    "pems = PEMS03(dtype = DTYPE, device = DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313658\n"
     ]
    }
   ],
   "source": [
    "sensor_index = 10\n",
    "sensor = pems.get_sensor(sensor_index)\n",
    "print(sensor)\n",
    "sample_index = 10\n",
    "\n",
    "ds1 = pems.get_sensor_dataset(sensor, dtype=torch.float32, behavior='deterministic')\n",
    "ds2 = pems.get_allsensors_dataset(behavior='deterministic')\n",
    "\n",
    "#pems.to_tensordict()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 313658 200\n",
      "tensor([-1.2489e-01,  4.0435e-01, -3.2837e-03, -5.3190e-04,  2.4754e+00,\n",
      "         6.1224e-02, -9.3969e-01])\n",
      "tensor([-1.2489e-01,  4.0435e-01, -3.2837e-03, -5.3190e-04,  1.0698e+00,\n",
      "         1.5162e-01, -9.3969e-01], device='cuda:0')\n",
      "tensor(506.) tensor(317., device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "x1,y1 = ds1[sample_index]\n",
    "x2,y2 = ds2[(ds2.train_split - 1) * sensor_index + 200 ]\n",
    "print(x1[0])\n",
    "print(x2[0])\n",
    "print(y1,y2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[314697, 314730, 315830, 315827, 314698, 317862, 315831, 313172, 313190, 315828, 313166, 317143, 313178, 315823, 317956, 315826, 317947, 317960, 315834, 317948]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 39\u001b[0m\n\u001b[0;32m     27\u001b[0m cm \u001b[38;5;241m=\u001b[39m CellModel(num_tokens \u001b[38;5;241m=\u001b[39m ds\u001b[38;5;241m.\u001b[39mmax_length, dim_token \u001b[38;5;241m=\u001b[39m ds\u001b[38;5;241m.\u001b[39mtoken_dim,\n\u001b[0;32m     28\u001b[0m                num_transformers \u001b[38;5;241m=\u001b[39m NTRANSF, num_heads \u001b[38;5;241m=\u001b[39m NHEADS, feed_forward \u001b[38;5;241m=\u001b[39m NTRANSFF, \n\u001b[0;32m     29\u001b[0m                transformer_activation \u001b[38;5;241m=\u001b[39m TRANSFACT,\n\u001b[0;32m     30\u001b[0m                mlp \u001b[38;5;241m=\u001b[39m MLP, mlp_dim \u001b[38;5;241m=\u001b[39m MLPD, mlp_activation \u001b[38;5;241m=\u001b[39m MLPACT,\n\u001b[0;32m     31\u001b[0m                use_moe \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m, num_experts \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m8\u001b[39m,\n\u001b[0;32m     32\u001b[0m                device \u001b[38;5;241m=\u001b[39m DEVICE, dtype \u001b[38;5;241m=\u001b[39m DTYPE)\n\u001b[0;32m     34\u001b[0m \u001b[38;5;66;03m#resume(cm, MODELS_PATH + 'PEMS03_cell_model_2_4_256_2_256_20241214.pt')\u001b[39;00m\n\u001b[0;32m     35\u001b[0m \n\u001b[0;32m     36\u001b[0m \n\u001b[0;32m     37\u001b[0m \u001b[38;5;66;03m#resume(cm, CHECKPOINT_FILE)\u001b[39;00m\n\u001b[1;32m---> 39\u001b[0m \u001b[43mtraining_loop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mDEVICE\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[43mbatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2048\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.00001\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     40\u001b[0m \u001b[43m              \u001b[49m\u001b[43mcheckpoint_file\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mCHECKPOINT_FILE\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\petro\\Dropbox\\Projetos\\futurelab\\posdoc\\st_nca\\st_nca\\st_nca\\pretrain.py:110\u001b[0m, in \u001b[0;36mtraining_loop\u001b[1;34m(DEVICE, dataset, model, display, **kwargs)\u001b[0m\n\u001b[0;32m    106\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(epochs):\n\u001b[0;32m    108\u001b[0m   checkpoint(model, checkpoint_file)\n\u001b[1;32m--> 110\u001b[0m   errors_train, map_train, errors_val, map_val \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mDEVICE\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_ldr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_ldr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    112\u001b[0m   error_train\u001b[38;5;241m.\u001b[39mappend(np\u001b[38;5;241m.\u001b[39mmean(errors_train))\n\u001b[0;32m    113\u001b[0m   mape_train\u001b[38;5;241m.\u001b[39mappend(np\u001b[38;5;241m.\u001b[39mmean(map_train))\n",
      "File \u001b[1;32mc:\\Users\\petro\\Dropbox\\Projetos\\futurelab\\posdoc\\st_nca\\st_nca\\st_nca\\pretrain.py:20\u001b[0m, in \u001b[0;36mtrain_step\u001b[1;34m(DEVICE, train, test, model, loss, mape, optim)\u001b[0m\n\u001b[0;32m     17\u001b[0m errors \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m     18\u001b[0m mapes \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m---> 20\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m X,y \u001b[38;5;129;01min\u001b[39;00m train:\n\u001b[0;32m     21\u001b[0m \n\u001b[0;32m     22\u001b[0m   \u001b[38;5;66;03m# Batch times\u001b[39;00m\n\u001b[0;32m     23\u001b[0m   \u001b[38;5;66;03m#start_time = time.time()\u001b[39;00m\n\u001b[0;32m     24\u001b[0m \n\u001b[0;32m     25\u001b[0m   \u001b[38;5;66;03m#Performance advice found at: https://pytorch.org/tutorials/recipes/recipes/tuning_guide.html\u001b[39;00m\n\u001b[0;32m     26\u001b[0m   \u001b[38;5;66;03m#optim.zero_grad()\u001b[39;00m\n\u001b[0;32m     27\u001b[0m   \u001b[38;5;28;01mfor\u001b[39;00m param \u001b[38;5;129;01min\u001b[39;00m model\u001b[38;5;241m.\u001b[39mparameters():\n\u001b[0;32m     28\u001b[0m     param\u001b[38;5;241m.\u001b[39mgrad \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torch\\utils\\data\\dataloader.py:701\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    698\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    699\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    700\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 701\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    702\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    703\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m    704\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable\n\u001b[0;32m    705\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    706\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called\n\u001b[0;32m    707\u001b[0m ):\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torch\\utils\\data\\dataloader.py:1448\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1445\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_data(data)\n\u001b[0;32m   1447\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_shutdown \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tasks_outstanding \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m-> 1448\u001b[0m idx, data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1449\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tasks_outstanding \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   1450\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable:\n\u001b[0;32m   1451\u001b[0m     \u001b[38;5;66;03m# Check for _IterableDatasetStopIteration\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torch\\utils\\data\\dataloader.py:1412\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._get_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1408\u001b[0m     \u001b[38;5;66;03m# In this case, `self._data_queue` is a `queue.Queue`,. But we don't\u001b[39;00m\n\u001b[0;32m   1409\u001b[0m     \u001b[38;5;66;03m# need to call `.task_done()` because we don't use `.join()`.\u001b[39;00m\n\u001b[0;32m   1410\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1411\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m-> 1412\u001b[0m         success, data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_try_get_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1413\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m success:\n\u001b[0;32m   1414\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torch\\utils\\data\\dataloader.py:1243\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._try_get_data\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m   1230\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_try_get_data\u001b[39m(\u001b[38;5;28mself\u001b[39m, timeout\u001b[38;5;241m=\u001b[39m_utils\u001b[38;5;241m.\u001b[39mMP_STATUS_CHECK_INTERVAL):\n\u001b[0;32m   1231\u001b[0m     \u001b[38;5;66;03m# Tries to fetch data from `self._data_queue` once for a given timeout.\u001b[39;00m\n\u001b[0;32m   1232\u001b[0m     \u001b[38;5;66;03m# This can also be used as inner loop of fetching without timeout, with\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1240\u001b[0m     \u001b[38;5;66;03m# Returns a 2-tuple:\u001b[39;00m\n\u001b[0;32m   1241\u001b[0m     \u001b[38;5;66;03m#   (bool: whether successfully get data, any: data if successful else None)\u001b[39;00m\n\u001b[0;32m   1242\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1243\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_data_queue\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1244\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[38;5;28;01mTrue\u001b[39;00m, data)\n\u001b[0;32m   1245\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m   1246\u001b[0m         \u001b[38;5;66;03m# At timeout and error, we manually check whether any worker has\u001b[39;00m\n\u001b[0;32m   1247\u001b[0m         \u001b[38;5;66;03m# failed. Note that this is the only mechanism for Windows to detect\u001b[39;00m\n\u001b[0;32m   1248\u001b[0m         \u001b[38;5;66;03m# worker failures.\u001b[39;00m\n",
      "File \u001b[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.10_3.10.3056.0_x64__qbz5n2kfra8p0\\lib\\multiprocessing\\queues.py:113\u001b[0m, in \u001b[0;36mQueue.get\u001b[1;34m(self, block, timeout)\u001b[0m\n\u001b[0;32m    111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m block:\n\u001b[0;32m    112\u001b[0m     timeout \u001b[38;5;241m=\u001b[39m deadline \u001b[38;5;241m-\u001b[39m time\u001b[38;5;241m.\u001b[39mmonotonic()\n\u001b[1;32m--> 113\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_poll\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m    114\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m Empty\n\u001b[0;32m    115\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_poll():\n",
      "File \u001b[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.10_3.10.3056.0_x64__qbz5n2kfra8p0\\lib\\multiprocessing\\connection.py:257\u001b[0m, in \u001b[0;36m_ConnectionBase.poll\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    255\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_closed()\n\u001b[0;32m    256\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_readable()\n\u001b[1;32m--> 257\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_poll\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.10_3.10.3056.0_x64__qbz5n2kfra8p0\\lib\\multiprocessing\\connection.py:330\u001b[0m, in \u001b[0;36mPipeConnection._poll\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    327\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_got_empty_message \u001b[38;5;129;01mor\u001b[39;00m\n\u001b[0;32m    328\u001b[0m             _winapi\u001b[38;5;241m.\u001b[39mPeekNamedPipe(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_handle)[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m):\n\u001b[0;32m    329\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m--> 330\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mbool\u001b[39m(\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.10_3.10.3056.0_x64__qbz5n2kfra8p0\\lib\\multiprocessing\\connection.py:879\u001b[0m, in \u001b[0;36mwait\u001b[1;34m(object_list, timeout)\u001b[0m\n\u001b[0;32m    876\u001b[0m                 ready_objects\u001b[38;5;241m.\u001b[39madd(o)\n\u001b[0;32m    877\u001b[0m                 timeout \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m--> 879\u001b[0m     ready_handles \u001b[38;5;241m=\u001b[39m \u001b[43m_exhaustive_wait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwaithandle_to_obj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkeys\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    880\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    881\u001b[0m     \u001b[38;5;66;03m# request that overlapped reads stop\u001b[39;00m\n\u001b[0;32m    882\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m ov \u001b[38;5;129;01min\u001b[39;00m ov_list:\n",
      "File \u001b[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.10_3.10.3056.0_x64__qbz5n2kfra8p0\\lib\\multiprocessing\\connection.py:811\u001b[0m, in \u001b[0;36m_exhaustive_wait\u001b[1;34m(handles, timeout)\u001b[0m\n\u001b[0;32m    809\u001b[0m ready \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m    810\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m L:\n\u001b[1;32m--> 811\u001b[0m     res \u001b[38;5;241m=\u001b[39m \u001b[43m_winapi\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mWaitForMultipleObjects\u001b[49m\u001b[43m(\u001b[49m\u001b[43mL\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    812\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m res \u001b[38;5;241m==\u001b[39m WAIT_TIMEOUT:\n\u001b[0;32m    813\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x500 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "NTRANSF = 2\n",
    "NHEADS = 4\n",
    "NTRANSFF = 256\n",
    "TRANSFACT = nn.GELU()\n",
    "MLP = 2\n",
    "MLPD = 256\n",
    "MLPACT = nn.GELU()\n",
    "\n",
    "MODELS_PATH = DEFAULT_PATH + 'weights\\\\PEMS03\\\\'\n",
    "\n",
    "CHECKPOINT_FILE = MODELS_PATH + 'cell_model_{}_{}_{}_{}_{}.pt'.format(NTRANSF,NHEADS,NTRANSFF,MLP,MLPD)\n",
    "\n",
    "#ds = pems.get_fewsensors_dataset([311930, 312564, 312807, 312900, 313172, 314697, 315938, 317141, 318135, 318443 ], dtype=torch.float32, behavior='selfsupervised')\n",
    "#ds = pems.get_sensor_dataset(311930, dtype=torch.float32, behavior='nondeterministic')\n",
    "ds, sensors = pems.get_breadth_dataset(314697, max_sensors=20, \n",
    "                                       dtype=DTYPE,\n",
    "                                       behavior='selfsupervised')\n",
    "\n",
    "print(sensors)\n",
    "\n",
    "#pems.to_tensordict()\n",
    "\n",
    "#ds = pems.get_allsensors_dataset(behavior='deterministic')\n",
    "\n",
    "ds = ds.to(DEVICE)\n",
    "\n",
    "cm = CellModel(num_tokens = ds.max_length, dim_token = ds.token_dim,\n",
    "               num_transformers = NTRANSF, num_heads = NHEADS, feed_forward = NTRANSFF, \n",
    "               transformer_activation = TRANSFACT,\n",
    "               mlp = MLP, mlp_dim = MLPD, mlp_activation = MLPACT,\n",
    "               use_moe = False, num_experts = 8,\n",
    "               device = DEVICE, dtype = DTYPE)\n",
    "\n",
    "#resume(cm, MODELS_PATH + 'PEMS03_cell_model_2_4_256_2_256_20241214.pt')\n",
    "\n",
    "\n",
    "#resume(cm, CHECKPOINT_FILE)\n",
    "\n",
    "training_loop(DEVICE, ds, cm,  batch=2048, epochs=10, lr=0.00001,\n",
    "              checkpoint_file= CHECKPOINT_FILE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from st_nca.common import MAPE, SMAPE\n",
    "def evaluate(model, in_sample, out_sample, num_samples = None):\n",
    "  metrics = {\"MAPE\": MAPE, \"SMAPE\": SMAPE}\n",
    "\n",
    "  model.eval()\n",
    "\n",
    "  results = {}\n",
    "\n",
    "  results['train'] = experiment_on_dataset(model, in_sample, num_samples, metrics)\n",
    "  results['test'] = experiment_on_dataset(model, out_sample, num_samples, metrics)\n",
    "\n",
    "  return results\n",
    "\n",
    "def experiment_on_dataset(model, sample, num_samples, metrics):\n",
    "    total = len(sample)\n",
    "    samples = num_samples if not num_samples is None else total\n",
    "    indexes = torch.randperm(total, device=model.device)[:samples]\n",
    "\n",
    "    X_batch = torch.zeros(samples, model.num_tokens, model.dim_token, \n",
    "                      device=model.device, dtype=model.dtype)\n",
    "    y_batch = torch.zeros(samples, device=model.device, dtype=model.dtype)\n",
    "  \n",
    "    for ct,ix in enumerate(indexes):\n",
    "      X,y = sample[ix]\n",
    "      X_batch[ct,:] = X\n",
    "      y_batch[ct] = y\n",
    "\n",
    "    #print(X_batch, y_batch)\n",
    "\n",
    "    out = model(X_batch)\n",
    "\n",
    "    #print(out)\n",
    "\n",
    "    res = {}\n",
    "    for key, metric in metrics.items():\n",
    "      res[key] = metric(y_batch, out).detach().cpu()\n",
    "\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train': {'MAPE': tensor(2.4232e+08), 'SMAPE': tensor(0.8460)},\n",
       " 'test': {'MAPE': tensor(2.0427e+08), 'SMAPE': tensor(0.8683)}}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NTRANSF = 2\n",
    "NHEADS = 4\n",
    "NTRANSFF = 256\n",
    "TRANSFACT = nn.GELU()\n",
    "MLP = 2\n",
    "MLPD = 256\n",
    "MLPACT = nn.GELU()\n",
    "\n",
    "MODELS_PATH = DEFAULT_PATH + 'weights\\\\PEMS03\\\\'\n",
    "\n",
    "CHECKPOINT_FILE = MODELS_PATH + 'cell_model_{}_{}_{}_{}_{}.pt'.format(NTRANSF,NHEADS,NTRANSFF,MLP,MLPD)\n",
    "\n",
    "pems.to_tensordict()\n",
    "\n",
    "ds = pems.get_allsensors_dataset(behavior='selfsupervised')\n",
    "\n",
    "ds = ds.to(DEVICE)\n",
    "\n",
    "cm = CellModel(num_tokens = ds.max_length, dim_token = ds.token_dim,\n",
    "               num_transformers = NTRANSF, num_heads = NHEADS, feed_forward = NTRANSFF, \n",
    "               transformer_activation = TRANSFACT,\n",
    "               mlp = MLP, mlp_dim = MLPD, mlp_activation = MLPACT,\n",
    "               use_moe = False, num_experts = 8,\n",
    "               device = DEVICE, dtype = DTYPE)\n",
    "\n",
    "resume(cm, CHECKPOINT_FILE)\n",
    "\n",
    "evaluate(model=cm, in_sample=ds.train(), out_sample=ds.test(), num_samples=15000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment Agenda\n",
    "\n",
    "Federated Graph Neural Cellular Automata - FedGNCA\n",
    "\n",
    "#### Cross Validation\n",
    "\n",
    "- 60% Training\n",
    "- 20% Validation\n",
    "- 20% Test\n",
    "\n",
    "#### H = Forecasting Horizons\n",
    "\n",
    "- ~H = 1 (5 minutes ahead)~\n",
    "- H = 12 (1 hour ahead)\n",
    "- ~H = 24 (2 hours ahead)~\n",
    "- ~H = 48 (4 hours ahead)~\n",
    "- ~H = 96 (8 hours ahead)~\n",
    "\n",
    "#### Metrics\n",
    "- Loss Function: MSE\n",
    "- Comparison Metrics\n",
    "  - MAPE \n",
    "  - RMSE\n",
    "  - MAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pems.num_samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graph CA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODELS_PATH = DEFAULT_PATH + 'weights\\\\PEMS03\\\\'\n",
    "\n",
    "DTYPE = torch.float32\n",
    "NTRANSF = 2\n",
    "NHEADS = 4\n",
    "NTRANSFF = 256\n",
    "TRANSFACT = nn.GELU()\n",
    "MLP = 2\n",
    "MLPD = 256\n",
    "MLPACT = nn.GELU()\n",
    "\n",
    "ds, sensors = pems.get_breadth_dataset(314697, max_sensors=20, \n",
    "                                       dtype=torch.float64,\n",
    "                                       behavior='deterministic')\n",
    "\n",
    "cm = CellModel(num_tokens = ds.max_length, dim_token = ds.token_dim,\n",
    "               num_transformers = NTRANSF, num_heads = NHEADS, feed_forward = NTRANSFF, \n",
    "               transformer_activation = TRANSFACT,\n",
    "               mlp = MLP, mlp_dim = MLPD, mlp_activation = MLPACT,\n",
    "               device = DEVICE, dtype = DTYPE)\n",
    "\n",
    "resume(cm, MODELS_PATH + 'cell_model_{}_{}_{}_{}_{}.pt'.format(NTRANSF,NHEADS,NTRANSFF,MLP,MLPD))\n",
    "\n",
    "subgraph = pems.G.subgraph(sensors)\n",
    "\n",
    "gca = GraphCellularAutomata(device=cm.device, dtype=cm.dtype, graph = subgraph,\n",
    "                            max_length = pems.max_length, token_size=pems.token_dim,\n",
    "                            tokenizer=pems.tokenizer, cell_model = cm)\n",
    "\n",
    "initial_date = datetime(year=2018, month=9, day=1, hour=23, minute=0)\n",
    "\n",
    "df = pems.data[(pems.data['timestamp'] == from_datetime_to_np(initial_date))]\n",
    "\n",
    "initial_state = {}\n",
    "for sensor in subgraph.nodes():\n",
    "    initial_state[str(sensor)] = df[str(sensor)].values[0]\n",
    "\n",
    "print(initial_state)\n",
    "\n",
    "gca.run(initial_date = initial_date, initial_stat = initial_state, \n",
    "        iterations = 10, increment_type='minute', increment=5,\n",
    "        return_type = 'tensordict')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine Tunning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from st_nca.finetune import FineTunningDataset, finetune_loop\n",
    "\n",
    "MODELS_PATH = DEFAULT_PATH + 'weights\\\\PEMS03\\\\'\n",
    "\n",
    "DTYPE = torch.float32\n",
    "NTRANSF = 2\n",
    "NHEADS = 4\n",
    "NTRANSFF = 256\n",
    "TRANSFACT = nn.GELU()\n",
    "MLP = 2\n",
    "MLPD = 256\n",
    "MLPACT = nn.GELU()\n",
    "\n",
    "ds, sensors = pems.get_breadth_dataset(314697, max_sensors=20, \n",
    "                                       dtype=DTYPE,\n",
    "                                       behavior='deterministic')\n",
    "\n",
    "cm = CellModel(num_tokens = ds.max_length, dim_token = ds.token_dim,\n",
    "               num_transformers = NTRANSF, num_heads = NHEADS, feed_forward = NTRANSFF, \n",
    "               transformer_activation = TRANSFACT,\n",
    "               mlp = MLP, mlp_dim = MLPD, mlp_activation = MLPACT,\n",
    "               device = DEVICE, dtype = DTYPE)\n",
    "\n",
    "resume(cm, MODELS_PATH + 'cell_model_{}_{}_{}_{}_{}.pt'.format(NTRANSF,NHEADS,NTRANSFF,MLP,MLPD))\n",
    "\n",
    "subgraph = pems.G.subgraph(sensors)\n",
    "\n",
    "gca = GraphCellularAutomata(device=DEVICE, dtype=DTYPE, graph = subgraph,\n",
    "                            max_length = pems.max_length, token_size=pems.token_dim,\n",
    "                            tokenizer=pems.tokenizer, cell_model = cm)\n",
    "\n",
    "finetune_ds = FineTunningDataset(pems, sensors, )\n",
    "\n",
    "finetune_loop(DEVICE, finetune_ds, gca, \n",
    "              iterations = 10, increment_type='minute', increment=5,\n",
    "              epochs = 10, batch = 50, lr = 0.0001,\n",
    "              checkpoint_file =  MODELS_PATH + 'gca_{}_{}_{}_{}_{}.pt'.format(NTRANSF,NHEADS,NTRANSFF,MLP,MLPD))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pems.num_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
